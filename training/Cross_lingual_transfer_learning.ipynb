{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnLwJRrULHEv"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install fsspec -q\n",
        "!pip install cmake dotenv hf-xet huggingface-hub\n",
        "!pip install pandas pillow protobuf python-dotenv\n",
        "!pip install safetensors\n",
        "!pip install scikit-learn tiktoken tokenizers\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install tqdm transformers datasets sentencepiece\n",
        "!pip install  --upgrade datasets fsspec --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37_fKqJ3NTdu"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from huggingface_hub import login\n",
        "from dotenv import load_dotenv\n",
        "import os, re, random\n",
        "import torch, numpy as np\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed()\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "login(token=os.getenv(\"HUGGING_FACE_HUB_TOKEN\"))\n",
        "\n",
        "\n",
        "datasets = {\n",
        "    \"eng\": load_dataset(\"brighter-dataset/BRIGHTER-emotion-categories\", \"eng\"),\n",
        "    \"zul\": load_dataset(\"brighter-dataset/BRIGHTER-emotion-categories\", \"zul\"),\n",
        "    \"pcm\": load_dataset(\"brighter-dataset/BRIGHTER-emotion-categories\", \"pcm\"),\n",
        "}\n",
        "\n",
        "emotion_labels = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    return text\n",
        "\n",
        "def preprocess(example):\n",
        "    example[\"text\"] = clean_text(example[\"text\"])\n",
        "    example[\"labels\"] = [float(example.get(label, 0) or 0) for label in emotion_labels]\n",
        "    return example\n",
        "\n",
        "for lang in datasets:\n",
        "    datasets[lang] = datasets[lang].map(preprocess)\n",
        "\n",
        "model_name = \"castorini/afriberta_base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "for lang in datasets:\n",
        "    datasets[lang] = datasets[lang].map(tokenize, batched=True)\n",
        "    datasets[lang].set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=len(emotion_labels),\n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = (torch.sigmoid(torch.tensor(logits)) > 0.5).int().numpy()\n",
        "    labels = labels.astype(int)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels.reshape(-1), preds.reshape(-1)),\n",
        "        \"f1\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n",
        "    }\n",
        "\n",
        "def get_trainer(model, train_dataset, eval_dataset, out_dir):\n",
        "    args = TrainingArguments(\n",
        "        output_dir=out_dir,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"no\",\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        num_train_epochs=3,\n",
        "        logging_steps=10,\n",
        "        report_to=\"none\",\n",
        "    )\n",
        "    return Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "\n",
        "print(\"Training on English...\")\n",
        "trainer = get_trainer(model, datasets[\"eng\"][\"train\"], datasets[\"eng\"][\"dev\"], \"./eng_model\")\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "print(\"\\nFine-tuning on Zulu...\")\n",
        "trainer.train_dataset = datasets[\"zul\"][\"dev\"]\n",
        "trainer.eval_dataset = datasets[\"zul\"][\"test\"]\n",
        "trainer.args.output_dir = \"./zul_model\"\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\nEvaluating on Zulu test set...\")\n",
        "zulu_test_results = trainer.predict(datasets[\"zul\"][\"test\"])\n",
        "zulu_metrics = compute_metrics((zulu_test_results.predictions, zulu_test_results.label_ids))\n",
        "print(\"Zulu F1:\", zulu_metrics[\"f1\"])\n",
        "\n",
        "\n",
        "print(\"\\nFine-tuning on Pidgin...\")\n",
        "trainer.train_dataset = datasets[\"pcm\"][\"train\"]\n",
        "trainer.eval_dataset = datasets[\"pcm\"][\"dev\"]\n",
        "trainer.args.output_dir = \"./pcm_model\"\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\nEvaluating on Pidgin test set...\")\n",
        "pcm_test_results = trainer.predict(datasets[\"pcm\"][\"test\"])\n",
        "pcm_metrics = compute_metrics((pcm_test_results.predictions, pcm_test_results.label_ids))\n",
        "print(\"Pidgin F1:\", pcm_metrics[\"f1\"])\n",
        "model.save_pretrained(\"./final_model\")\n",
        "tokenizer.save_pretrained(\"./final_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWITDqhQTun3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "zulu_preds_output = trainer.predict(datasets[\"zul\"][\"test\"])\n",
        "logits = torch.tensor(zulu_preds_output.predictions)\n",
        "preds = (torch.sigmoid(logits) > 0.5).int().numpy()\n",
        "labels = zulu_preds_output.label_ids.astype(int)\n",
        "flat_preds = preds.reshape(-1)\n",
        "flat_labels = labels.reshape(-1)\n",
        "\n",
        "\n",
        "zulu_accuracy = accuracy_score(flat_labels, flat_preds)\n",
        "zulu_f1_macro = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
        "zulu_report = classification_report(labels, preds, target_names=emotion_labels, zero_division=0)\n",
        "\n",
        "print(\"Zulu Accuracy:\", zulu_accuracy)\n",
        "print(\"Zulu Macro F1:\", zulu_f1_macro)\n",
        "print(\"\\nZulu Classification Report:\\n\", zulu_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqT8wmedT_N6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "pcm_preds_output = trainer.predict(datasets[\"pcm\"][\"test\"])\n",
        "logits = torch.tensor(pcm_preds_output.predictions)\n",
        "preds = (torch.sigmoid(logits) > 0.5).int().numpy()\n",
        "labels = pcm_preds_output.label_ids.astype(int)\n",
        "\n",
        "pcm_accuracy = accuracy_score(labels.reshape(-1), preds.reshape(-1))\n",
        "pcm_f1_macro = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
        "pcm_report = classification_report(labels, preds, target_names=emotion_labels, zero_division=0)\n",
        "\n",
        "print(\"Pidgin Accuracy:\", pcm_accuracy)\n",
        "print(\"Pidgin Macro F1:\", pcm_f1_macro)\n",
        "print(\"\\nPidgin Classification Report:\\n\", pcm_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "\n",
        "model_path = \"./final_model\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "emotion_labels = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n",
        "\n",
        "\n",
        "sentence = \"I dey happy well well today!\"\n",
        "\n",
        "\n",
        "inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    probs = torch.sigmoid(outputs.logits).squeeze().numpy()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(emotion_labels, probs, color='skyblue')\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.title(\"Emotion Probabilities for Pidgin Sentence\")\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print({label: round(float(prob), 3) for label, prob in zip(emotion_labels, probs)})"
      ],
      "metadata": {
        "id": "hz65B43ELb09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "\n",
        "model_path = \"./final_model\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "emotion_labels = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n",
        "\n",
        "\n",
        "sentence = \"Kusolwa umkhuba ekhaya ngotholwe emotweni yake eseshonile esonakele\"\n",
        "\n",
        "\n",
        "inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    probs = torch.sigmoid(outputs.logits).squeeze().numpy()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(emotion_labels, probs, color='skyblue')\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.title(\"Emotion Probabilities for Pidgin Sentence\")\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NOlT6uMiNutj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEApd682vPX7"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade shap\n",
        "!pip install bertviz lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWJ94slzrqUT"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "model_path = \"./final_model\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "model.eval()\n",
        "texts = [\"Kusolwa umkhuba ekhaya ngotholwe emotweni yake eseshonile esonakele\"]\n",
        "\n",
        "\n",
        "print(\"Testing predict function...\")\n",
        "\n",
        "\n",
        "def predict(texts):\n",
        "\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "    elif not isinstance(texts, list):\n",
        "        texts = [str(texts)]\n",
        "\n",
        "\n",
        "    processed_texts = []\n",
        "    for text in texts:\n",
        "        if isinstance(text, str) and text.strip():\n",
        "            processed_texts.append(text.strip())\n",
        "        else:\n",
        "            processed_texts.append(\"empty\")\n",
        "\n",
        "    try:\n",
        "\n",
        "        inputs = tokenizer(processed_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            probs = torch.sigmoid(outputs.logits).cpu().numpy()\n",
        "\n",
        "        return probs\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in predict: {e}\")\n",
        "\n",
        "        return np.zeros((len(processed_texts), model.config.num_labels))\n",
        "\n",
        "\n",
        "test_pred = predict(texts)\n",
        "print(f\"Test prediction shape: {test_pred.shape}\")\n",
        "print(f\"Test prediction: {test_pred}\")\n",
        "\n",
        "\n",
        "test_batch = predict([texts[0], \"hello world\"])\n",
        "print(f\"Batch prediction shape: {test_batch.shape}\")\n",
        "\n",
        "\n",
        "print(\"\\nCreating SHAP explainer...\")\n",
        "\n",
        "\n",
        "try:\n",
        "    from transformers import pipeline\n",
        "\n",
        "\n",
        "    def pipeline_predict(texts):\n",
        "        if isinstance(texts, str):\n",
        "            texts = [texts]\n",
        "\n",
        "\n",
        "        text_list = [str(text) for text in texts]\n",
        "\n",
        "\n",
        "        inputs = tokenizer(text_list, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            probs = torch.sigmoid(outputs.logits).cpu().numpy()\n",
        "\n",
        "        return probs\n",
        "\n",
        "\n",
        "    explainer = shap.Explainer(pipeline_predict, shap.maskers.Text(tokenizer))\n",
        "\n",
        "    print(\"Computing SHAP values...\")\n",
        "    shap_values = explainer(texts, max_evals=100)\n",
        "\n",
        "\n",
        "    shap.plots.text(shap_values[0])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"SHAP with Text masker failed: {e}\")\n",
        "\n",
        "\n",
        "    print(\"Falling back to manual explanation...\")\n",
        "\n",
        "    original_text = texts[0]\n",
        "    tokens = original_text.split()\n",
        "\n",
        "\n",
        "    baseline_pred = predict([original_text])[0]\n",
        "\n",
        "    print(f\"Original text: {original_text}\")\n",
        "    print(f\"Baseline prediction: {baseline_pred}\")\n",
        "    print(\"\\nWord-level importance analysis:\")\n",
        "\n",
        "    word_importances = []\n",
        "    for i, word in enumerate(tokens):\n",
        "\n",
        "        masked_tokens = tokens.copy()\n",
        "        masked_tokens[i] = \"[MASK]\"\n",
        "        masked_text = \" \".join(masked_tokens)\n",
        "\n",
        "\n",
        "        masked_pred = predict([masked_text])[0]\n",
        "\n",
        "\n",
        "        importance = baseline_pred - masked_pred\n",
        "        word_importances.append(importance)\n",
        "\n",
        "        print(f\"  '{word}': {importance}\")\n",
        "\n",
        "\n",
        "    print(f\"\\nSimple text visualization:\")\n",
        "    for word, importance in zip(tokens, word_importances):\n",
        "\n",
        "        emphasis = \"**\" if np.max(np.abs(importance)) > 0.01 else \"\"\n",
        "        print(f\"{emphasis}{word}{emphasis}\", end=\" \")\n",
        "    print()\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Alternative: Using LIME for text explanation\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "\n",
        "    lime_explainer = LimeTextExplainer(class_names=[f'class_{i}' for i in range(model.config.num_labels)])\n",
        "\n",
        "\n",
        "    def lime_predict(texts):\n",
        "        probs = predict(texts)\n",
        "        return probs\n",
        "\n",
        "    exp = lime_explainer.explain_instance(\n",
        "        texts[0],\n",
        "        lime_predict,\n",
        "        num_features=10,\n",
        "        num_samples=100\n",
        "    )\n",
        "\n",
        "    print(\"LIME explanation:\")\n",
        "    exp.show_in_notebook(text=True)\n",
        "\n",
        "\n",
        "    print(\"\\nLIME feature weights:\")\n",
        "    for feature, weight in exp.as_list():\n",
        "        print(f\"  '{feature}': {weight}\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"LIME not available. Install with: pip install lime\")\n",
        "except Exception as e:\n",
        "    print(f\"LIME explanation failed: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nuc-X7sbtch5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from bertviz import model_view, head_view\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "text = \"I dey happy well well today!\"\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Analyzing text: '{text}'\")\n",
        "print(f\"Model type: {type(model)}\")\n",
        "print(f\"Model config: {model.config}\")\n",
        "\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=True)\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "\n",
        "print(f\"Tokens: {tokens}\")\n",
        "print(f\"Number of tokens: {len(tokens)}\")\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs, output_attentions=True, return_dict=True)\n",
        "\n",
        "\n",
        "attention = outputs.attentions\n",
        "print(f\"Number of attention layers: {len(attention)}\")\n",
        "print(f\"Attention shape per layer: {attention[0].shape}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"METHOD 1: Model View\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "\n",
        "    attention_tensor = torch.stack(attention)\n",
        "\n",
        "\n",
        "    model_view(\n",
        "        attention=attention_tensor,\n",
        "        tokens=tokens,\n",
        "        sentence_b_start=None,\n",
        "        prettify_tokens=True,\n",
        "        display_mode='light'\n",
        "    )\n",
        "    print(\"Model view displayed successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Model view failed: {e}\")\n",
        "    print(\"This might be due to Jupyter notebook requirements or display issues.\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"METHOD 2: Head View\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    head_view(\n",
        "        attention=attention_tensor,\n",
        "        tokens=tokens,\n",
        "        sentence_b_start=None,\n",
        "        prettify_tokens=True,\n",
        "        display_mode='light'\n",
        "    )\n",
        "    print(\"Head view displayed successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Head view failed: {e}\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"METHOD 3: Manual Attention Analysis\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def analyze_attention_patterns(attention_weights, tokens):\n",
        "    \"\"\"Analyze and print attention patterns manually\"\"\"\n",
        "\n",
        "    num_layers = len(attention_weights)\n",
        "    num_heads = attention_weights[0].shape[1]\n",
        "    seq_len = len(tokens)\n",
        "\n",
        "    print(f\"Model has {num_layers} layers with {num_heads} heads each\")\n",
        "    print(f\"Sequence length: {seq_len} tokens\")\n",
        "\n",
        "\n",
        "    for layer_idx, layer_attention in enumerate(attention_weights):\n",
        "        print(f\"\\n--- Layer {layer_idx + 1} ---\")\n",
        "\n",
        "\n",
        "        avg_attention = layer_attention[0].mean(dim=0)\n",
        "\n",
        "\n",
        "        for i, token in enumerate(tokens):\n",
        "            if token in ['[CLS]', '[SEP]', '[PAD]']:\n",
        "                continue\n",
        "\n",
        "\n",
        "            from_token_attention = avg_attention[i]\n",
        "            top_indices = torch.topk(from_token_attention, k=min(3, len(tokens))).indices\n",
        "\n",
        "            print(f\"  '{token}' pays most attention to:\")\n",
        "            for idx in top_indices:\n",
        "                attention_score = from_token_attention[idx].item()\n",
        "                target_token = tokens[idx]\n",
        "                print(f\"    '{target_token}': {attention_score:.3f}\")\n",
        "\n",
        "\n",
        "    print(f\"\\n--- Overall Attention Summary ---\")\n",
        "\n",
        "\n",
        "    all_attention = torch.stack(attention_weights).mean(dim=(0, 2))\n",
        "\n",
        "\n",
        "    total_attention_received = all_attention[0].sum(dim=0)\n",
        "    print(\"Tokens ranked by total attention received:\")\n",
        "    sorted_indices = torch.argsort(total_attention_received, descending=True)\n",
        "\n",
        "    for rank, idx in enumerate(sorted_indices[:5]):\n",
        "        token = tokens[idx]\n",
        "        attention_score = total_attention_received[idx].item()\n",
        "        print(f\"  {rank+1}. '{token}': {attention_score:.3f}\")\n",
        "\n",
        "\n",
        "analyze_attention_patterns(attention, tokens)\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"METHOD 4: Attention Heatmap\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "\n",
        "    layer_to_viz = 0\n",
        "    head_to_viz = 0\n",
        "\n",
        "\n",
        "    specific_attention = attention[layer_to_viz][0, head_to_viz].cpu().numpy()\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(\n",
        "        specific_attention,\n",
        "        xticklabels=tokens,\n",
        "        yticklabels=tokens,\n",
        "        annot=True,\n",
        "        fmt='.2f',\n",
        "        cmap='Blues',\n",
        "        cbar=True\n",
        "    )\n",
        "    plt.title(f'Attention Heatmap - Layer {layer_to_viz + 1}, Head {head_to_viz + 1}')\n",
        "    plt.xlabel('Attending to (Keys)')\n",
        "    plt.ylabel('Attending from (Queries)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Heatmap created for Layer {layer_to_viz + 1}, Head {head_to_viz + 1}\")\n",
        "\n",
        "    avg_attention_all = torch.stack(attention).mean(dim=(0, 2))[0].cpu().numpy()\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(\n",
        "        avg_attention_all,\n",
        "        xticklabels=tokens,\n",
        "        yticklabels=tokens,\n",
        "        annot=True,\n",
        "        fmt='.2f',\n",
        "        cmap='Reds',\n",
        "        cbar=True\n",
        "    )\n",
        "    plt.title('Average Attention Across All Layers and Heads')\n",
        "    plt.xlabel('Attending to (Keys)')\n",
        "    plt.ylabel('Attending from (Queries)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "except ImportError:\n",
        "    print(\"Matplotlib/Seaborn not available for heatmap visualization\")\n",
        "except Exception as e:\n",
        "    print(f\"Heatmap creation failed: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"METHOD 5: Interactive Analysis Functions\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def get_attention_for_token(token_text, layer_idx=None, head_idx=None):\n",
        "    \"\"\"Get attention patterns for a specific token\"\"\"\n",
        "    try:\n",
        "        token_idx = tokens.index(token_text)\n",
        "    except ValueError:\n",
        "        print(f\"Token '{token_text}' not found in: {tokens}\")\n",
        "        return\n",
        "\n",
        "    if layer_idx is None:\n",
        "        avg_attention = torch.stack(attention).mean(dim=0)\n",
        "        if head_idx is None:\n",
        "            token_attention = avg_attention[0].mean(dim=0)[token_idx]\n",
        "            print(f\"Average attention from '{token_text}' to all tokens:\")\n",
        "        else:\n",
        "            token_attention = avg_attention[0, head_idx][token_idx]\n",
        "            print(f\"Attention from '{token_text}' (head {head_idx}) to all tokens:\")\n",
        "    else:\n",
        "        if head_idx is None:\n",
        "            token_attention = attention[layer_idx][0].mean(dim=0)[token_idx]\n",
        "            print(f\"Attention from '{token_text}' (layer {layer_idx}) to all tokens:\")\n",
        "        else:\n",
        "            token_attention = attention[layer_idx][0, head_idx][token_idx]\n",
        "            print(f\"Attention from '{token_text}' (layer {layer_idx}, head {head_idx}) to all tokens:\")\n",
        "\n",
        "\n",
        "    sorted_indices = torch.argsort(token_attention, descending=True)\n",
        "    for idx in sorted_indices:\n",
        "        target_token = tokens[idx]\n",
        "        score = token_attention[idx].item()\n",
        "        print(f\"  '{target_token}': {score:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\nExample: Attention from 'happy':\")\n",
        "get_attention_for_token('happy')\n",
        "\n",
        "print(\"\\nExample: Attention from 'nervous':\")\n",
        "get_attention_for_token('nervous')\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ATTENTION INSIGHTS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "\n",
        "def analyze_attention_types():\n",
        "    \"\"\"Analyze different types of attention patterns\"\"\"\n",
        "\n",
        "\n",
        "    avg_attention = torch.stack(attention).mean(dim=(0, 2))[0]\n",
        "\n",
        "    print(\"Self-attention scores (diagonal values):\")\n",
        "    for i, token in enumerate(tokens):\n",
        "        if token not in ['[CLS]', '[SEP]', '[PAD]']:\n",
        "            self_attention = avg_attention[i, i].item()\n",
        "            print(f\"  '{token}': {self_attention:.4f}\")\n",
        "\n",
        "    print(\"\\nStrongest cross-token attention pairs:\")\n",
        "\n",
        "    mask = ~torch.eye(len(tokens), dtype=bool)\n",
        "    masked_attention = avg_attention.clone()\n",
        "    masked_attention[~mask] = 0\n",
        "\n",
        "\n",
        "    flat_attention = masked_attention.flatten()\n",
        "    top_k = 5\n",
        "    top_indices = torch.topk(flat_attention, k=top_k).indices\n",
        "\n",
        "    for idx in top_indices:\n",
        "        i = idx // len(tokens)\n",
        "        j = idx % len(tokens)\n",
        "        score = avg_attention[i, j].item()\n",
        "        from_token = tokens[i]\n",
        "        to_token = tokens[j]\n",
        "        print(f\"  '{from_token}' -> '{to_token}': {score:.4f}\")\n",
        "\n",
        "analyze_attention_types()\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(\"BertViz analysis complete!\")\n",
        "print(\"For best visualization, run this in a Jupyter notebook with:\")\n",
        "print(\"!pip install bertviz\")\n",
        "print(\"from bertviz import model_view, head_view\")\n",
        "print(f\"{'='*50}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDc5bUfrxxrl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from bertviz import model_view, head_view\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "text = \"I am very happy today but also a bit nervous.\"\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Analyzing text: '{text}'\")\n",
        "print(f\"Model type: {type(model)}\")\n",
        "print(f\"Model config: {model.config}\")\n",
        "\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=True)\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "\n",
        "print(f\"Tokens: {tokens}\")\n",
        "print(f\"Number of tokens: {len(tokens)}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs, output_attentions=True, return_dict=True)\n",
        "\n",
        "\n",
        "attention = outputs.attentions\n",
        "print(f\"Number of attention layers: {len(attention)}\")\n",
        "print(f\"Attention shape per layer: {attention[0].shape}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"METHOD 1: Model View\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "\n",
        "    attention_tensor = torch.stack(attention)\n",
        "\n",
        "    model_view(\n",
        "        attention=attention_tensor,\n",
        "        tokens=tokens,\n",
        "        sentence_b_start=None,\n",
        "        prettify_tokens=True,\n",
        "        display_mode='light'\n",
        "    )\n",
        "    print(\"Model view displayed successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Model view failed: {e}\")\n",
        "    print(\"This might be due to Jupyter notebook requirements or display issues.\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"METHOD 2: Head View\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    head_view(\n",
        "        attention=attention_tensor,\n",
        "        tokens=tokens,\n",
        "        sentence_b_start=None,\n",
        "        prettify_tokens=True,\n",
        "        display_mode='light'\n",
        "    )\n",
        "    print(\"Head view displayed successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Head view failed: {e}\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"METHOD 3: Manual Attention Analysis\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def analyze_attention_patterns(attention_weights, tokens):\n",
        "    \"\"\"Analyze and print attention patterns manually\"\"\"\n",
        "\n",
        "    num_layers = len(attention_weights)\n",
        "    num_heads = attention_weights[0].shape[1]\n",
        "    seq_len = len(tokens)\n",
        "\n",
        "    print(f\"Model has {num_layers} layers with {num_heads} heads each\")\n",
        "    print(f\"Sequence length: {seq_len} tokens\")\n",
        "\n",
        "\n",
        "    for layer_idx, layer_attention in enumerate(attention_weights):\n",
        "        print(f\"\\n--- Layer {layer_idx + 1} ---\")\n",
        "\n",
        "\n",
        "        avg_attention = layer_attention[0].mean(dim=0)\n",
        "        for i, token in enumerate(tokens):\n",
        "            if token in ['[CLS]', '[SEP]', '[PAD]']:\n",
        "                continue\n",
        "\n",
        "\n",
        "            from_token_attention = avg_attention[i]\n",
        "            top_indices = torch.topk(from_token_attention, k=min(3, len(tokens))).indices\n",
        "\n",
        "            print(f\"  '{token}' pays most attention to:\")\n",
        "            for idx in top_indices:\n",
        "                attention_score = from_token_attention[idx].item()\n",
        "                target_token = tokens[idx]\n",
        "                print(f\"    '{target_token}': {attention_score:.3f}\")\n",
        "\n",
        "\n",
        "    print(f\"\\n--- Overall Attention Summary ---\")\n",
        "\n",
        "\n",
        "    all_attention = torch.stack(attention_weights).mean(dim=(0, 2))\n",
        "    total_attention_received = all_attention[0].sum(dim=0)\n",
        "\n",
        "    print(\"Tokens ranked by total attention received:\")\n",
        "    sorted_indices = torch.argsort(total_attention_received, descending=True)\n",
        "\n",
        "    for rank, idx in enumerate(sorted_indices[:5]):\n",
        "        token = tokens[idx]\n",
        "        attention_score = total_attention_received[idx].item()\n",
        "        print(f\"  {rank+1}. '{token}': {attention_score:.3f}\")\n",
        "\n",
        "\n",
        "analyze_attention_patterns(attention, tokens)\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"METHOD 4: Attention Heatmap\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "\n",
        "    layer_to_viz = 0\n",
        "    head_to_viz = 0\n",
        "\n",
        "\n",
        "    specific_attention = attention[layer_to_viz][0, head_to_viz].cpu().numpy()\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(\n",
        "        specific_attention,\n",
        "        xticklabels=tokens,\n",
        "        yticklabels=tokens,\n",
        "        annot=True,\n",
        "        fmt='.2f',\n",
        "        cmap='Blues',\n",
        "        cbar=True\n",
        "    )\n",
        "    plt.title(f'Attention Heatmap - Layer {layer_to_viz + 1}, Head {head_to_viz + 1}')\n",
        "    plt.xlabel('Attending to (Keys)')\n",
        "    plt.ylabel('Attending from (Queries)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Heatmap created for Layer {layer_to_viz + 1}, Head {head_to_viz + 1}\")\n",
        "\n",
        "\n",
        "    avg_attention_all = torch.stack(attention).mean(dim=(0, 2))[0].cpu().numpy()\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(\n",
        "        avg_attention_all,\n",
        "        xticklabels=tokens,\n",
        "        yticklabels=tokens,\n",
        "        annot=True,\n",
        "        fmt='.2f',\n",
        "        cmap='Reds',\n",
        "        cbar=True\n",
        "    )\n",
        "    plt.title('Average Attention Across All Layers and Heads')\n",
        "    plt.xlabel('Attending to (Keys)')\n",
        "    plt.ylabel('Attending from (Queries)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "except ImportError:\n",
        "    print(\"Matplotlib/Seaborn not available for heatmap visualization\")\n",
        "except Exception as e:\n",
        "    print(f\"Heatmap creation failed: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"METHOD 5: Interactive Analysis Functions\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def get_attention_for_token(token_text, layer_idx=None, head_idx=None):\n",
        "    \"\"\"Get attention patterns for a specific token\"\"\"\n",
        "    try:\n",
        "        token_idx = tokens.index(token_text)\n",
        "    except ValueError:\n",
        "        print(f\"Token '{token_text}' not found in: {tokens}\")\n",
        "        return\n",
        "\n",
        "    if layer_idx is None:\n",
        "\n",
        "        avg_attention = torch.stack(attention).mean(dim=0)\n",
        "        if head_idx is None:\n",
        "\n",
        "            token_attention = avg_attention[0].mean(dim=0)[token_idx]\n",
        "            print(f\"Average attention from '{token_text}' to all tokens:\")\n",
        "        else:\n",
        "            token_attention = avg_attention[0, head_idx][token_idx]\n",
        "            print(f\"Attention from '{token_text}' (head {head_idx}) to all tokens:\")\n",
        "    else:\n",
        "        if head_idx is None:\n",
        "\n",
        "            token_attention = attention[layer_idx][0].mean(dim=0)[token_idx]\n",
        "            print(f\"Attention from '{token_text}' (layer {layer_idx}) to all tokens:\")\n",
        "        else:\n",
        "            token_attention = attention[layer_idx][0, head_idx][token_idx]\n",
        "            print(f\"Attention from '{token_text}' (layer {layer_idx}, head {head_idx}) to all tokens:\")\n",
        "\n",
        "\n",
        "    sorted_indices = torch.argsort(token_attention, descending=True)\n",
        "    for idx in sorted_indices:\n",
        "        target_token = tokens[idx]\n",
        "        score = token_attention[idx].item()\n",
        "        print(f\"  '{target_token}': {score:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\nExample: Attention from 'happy':\")\n",
        "get_attention_for_token('happy')\n",
        "\n",
        "print(\"\\nExample: Attention from 'nervous':\")\n",
        "get_attention_for_token('nervous')\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ATTENTION INSIGHTS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "\n",
        "def analyze_attention_types():\n",
        "    \"\"\"Analyze different types of attention patterns\"\"\"\n",
        "\n",
        "\n",
        "    avg_attention = torch.stack(attention).mean(dim=(0, 2))[0]\n",
        "\n",
        "    print(\"Self-attention scores (diagonal values):\")\n",
        "    for i, token in enumerate(tokens):\n",
        "        if token not in ['[CLS]', '[SEP]', '[PAD]']:\n",
        "            self_attention = avg_attention[i, i].item()\n",
        "            print(f\"  '{token}': {self_attention:.4f}\")\n",
        "\n",
        "    print(\"\\nStrongest cross-token attention pairs:\")\n",
        "\n",
        "    mask = ~torch.eye(len(tokens), dtype=bool)\n",
        "    masked_attention = avg_attention.clone()\n",
        "    masked_attention[~mask] = 0\n",
        "\n",
        "\n",
        "    flat_attention = masked_attention.flatten()\n",
        "    top_k = 5\n",
        "    top_indices = torch.topk(flat_attention, k=top_k).indices\n",
        "\n",
        "    for idx in top_indices:\n",
        "        i = idx // len(tokens)\n",
        "        j = idx % len(tokens)\n",
        "        score = avg_attention[i, j].item()\n",
        "        from_token = tokens[i]\n",
        "        to_token = tokens[j]\n",
        "        print(f\"  '{from_token}' -> '{to_token}': {score:.4f}\")\n",
        "\n",
        "analyze_attention_types()\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(\"BertViz analysis complete!\")\n",
        "print(\"For best visualization, run this in a Jupyter notebook with:\")\n",
        "print(\"!pip install bertviz\")\n",
        "print(\"from bertviz import model_view, head_view\")\n",
        "print(f\"{'='*50}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}